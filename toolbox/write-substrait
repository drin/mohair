#!/usr/bin/env python

# ------------------------------
# License

# Copyright 2024 Aldrin Montana
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# ------------------------------
# Overview
"""
Write a query plan in substrait using ibis.
"""


# ------------------------------
# Dependencies

# >> Standard modules
import os
import sys

from pathlib import Path

# >> Third-party
import pyarrow
# import pandas
import ibis

from ibis import udf
from ibis_substrait.compiler.core import SubstraitCompiler
from ibis_substrait.compiler.core import stp as substrait # substrait.plan_pb2 module


# >> Internal
from mohair.util            import ArgparseBuilder
from mohair.query.extension import SkyTable
from mohair.query.types     import ( SkyDomain
                                    ,SkyPartition
                                    ,SkyPartitionMeta
                                    ,SkyPartitionSlice)

# >> Functions
from mohair.util import TableFromBinary, SchemaFromBinary


# ------------------------------
# Module variables
SAMPLE_FPATH  = Path('resources') / 'sample-data.tsv'
SAMPLE_SCHEMA = pyarrow.schema([
     pyarrow.field('gene_id'   , pyarrow.string())
    ,pyarrow.field('cell_id'   , pyarrow.string())
    ,pyarrow.field('expression', pyarrow.float32())
])


# ------------------------------
# Parse CLI arguments first
if __name__ == '__main__':
    parsed_args, extra_args = (
        ArgparseBuilder.with_description('Write a substrait plan for a sample query')
                       .add_skytether_domain_arg(required=True)
                       .add_skytether_partition_arg(required=True)
                       .add_input_dir_arg(
                            required=True
                           ,help_str='Path to directory containing source domain'
                        )
                       .add_output_file_arg(
                            help_str='Path to write resulting substrait plan message'
                           ,default_fpath=os.path.join(
                                'resources', 'average-expression.substrait'
                            )
                        )
                       .parse_args()
    )

    # Validate args
    substrait_fpath = Path(parsed_args.output_file)
    if substrait_fpath.is_file():
        sys.exit(f'Output file already exists: "{substrait_fpath}"')


def TableFromTSV(data_fpath: Path = SAMPLE_FPATH) -> pyarrow.Table:
    """
    Convenience function that creates an arrow table from :data_fpath: using hard-coded
    assumptions.
    """

    # read data from the given file; assume 3 columns (see `SAMPLE_SCHEMA`)
    with open(data_fpath) as data_handle:
        col_names   = next(data_handle).split(' ')
        data_by_col = [ [] for _ in col_names ]

        for line in data_handle:
            fields = line.strip().split(' ')

            data_by_col[0].append(fields[0])
            data_by_col[1].append(fields[1])
            data_by_col[2].append(float(fields[2]))

    # construct the table and return it
    return pyarrow.Table.from_arrays(
         [
              pyarrow.array(data_by_col[0], type=pyarrow.string())
             ,pyarrow.array(data_by_col[1], type=pyarrow.string())
             ,pyarrow.array(data_by_col[2], type=pyarrow.float32())
         ]
        ,schema=SAMPLE_SCHEMA
    )

def WriteSubstraitToFile(substrait_msg: substrait.Plan) -> str:
    with substrait_fpath.open('wb') as file_handle:
        file_handle.write(substrait_msg.SerializeToString())

    return str(substrait_fpath)


def TStatAccumulate(data_table):
    squared_expr = data_table['expr_val'] * data_table['expr_val']

    return (
        data_table.group_by(data_table.feature_name)
                  .aggregate(
                        cell_count=data_table.count()
                       ,expr_total=(data_table['expr_val'].sum())
                       ,expr_sumsq=squared_expr.sum()
                   )
    )

def TStatCombine(left_table, right_table):
    return (
        left_table.join(right_table, left_table.feature_name == right_table.feature_name)
                  .select(
                        left_table['feature_name'].name('feature_name')
                       ,(left_table['cell_count'] + right_table['cell_count']).name('cell_count')
                       ,(left_table['expr_total'] + right_table['expr_total']).name('expr_total')
                       ,(left_table['expr_sumsq'] + right_table['expr_sumsq']).name('expr_sumsq')
                   )
    )

def TStatComplete(data_table):
    expr_avg = data_table.expr_total / data_table.cell_count
    expr_var = (data_table.expr_sumsq / data_table.cell_count) - (expr_avg * expr_avg)

    return data_table.select(
         data_table.feature_name
        ,expr_avg.name('expr_avg')
        ,expr_var.name('expr_var')
    )


# ------------------------------
# Main logic

if __name__ == '__main__':
    # Initialize domain and partitions
    sky_domain = SkyDomain(parsed_args.domain_key)
    sky_partitions = [
        sky_domain.PartitionFor(partition_key)
        for partition_key in parsed_args.partition_keys
    ]

    # Populate schemas and optionally data
    for sky_partition in sky_partitions:
        partition_fpath = Path(parsed_args.input_dir) / sky_partition.name()
        with open(partition_fpath, 'rb') as partition_handle:
            partition_schema = SchemaFromBinary(partition_handle.read())
            partition_schema = (
                # hard-coded way to change 3rd column's type to int32
                partition_schema.set(
                     2
                    ,partition_schema.field(2)
                                     .with_type(pyarrow.int32())
                )
            )
            print(partition_schema)
            # NOTE: we don't need table data for writing a substrait plan
            # partition_data = TableFromBinary(partition_handle.read())

        sky_partition.SetSchema(partition_schema)
        # sky_partition.SetData(partition_data)

    # create a query using the schemas in :sky_partitions:
    tstat_query = TStatAccumulate(SkyTable.FromPartition(sky_partitions[0]).to_expr())
    for sky_partition in sky_partitions[1:]:
        partition_query = TStatAccumulate(SkyTable.FromPartition(sky_partition).to_expr())
        tstat_query     = TStatCombine(tstat_query, partition_query)

    # final projection
    tstat_query = TStatComplete(tstat_query)

    print(tstat_query.unbind())

    substrait_compiler = SubstraitCompiler()
    proto_msg = substrait_compiler.compile(tstat_query.unbind())

    WriteSubstraitToFile(proto_msg)

